blocks:
  - name: aws-nodes
    content:
      nodes:
        - name: gpu-enabled
          $cndi.comment(aws_vantage): https://instances.vantage.sh/aws/ec2/g6.xlarge?region=us-east-1
          instance_type: g6.xlarge
          count: 2
          disk_size: 200

  - name: azure-nodes
    content:
      nodes:
        - name: gpugroup
          $cndi.comment(azure_vantage): https://instances.vantage.sh/azure/vm/nc4ast4-v3
          instance_type: Standard_NC4as_T4_v3
          count: 2
          disk_size: 200

  - name: gcp-nodes
    content:
      nodes:
        - name: gpu-enabled
          instance_type: g2-standard-4
          count: 2
          disk_size: 200

  - name: gcp-resource-quota
    content:
      apiVersion: v1
      kind: ResourceQuota
      metadata:
        name: gpu-operator-quota
        namespace: gpu-operator
      spec:
        hard:
          pods: 100
        scopeSelector:
          matchExpressions:
            - operator: In
              scopeName: PriorityClass
              values:
                - system-node-critical
                - system-cluster-critical

prompts:
  - $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/common/cluster/core-prompts.yaml):
      {}
  - $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/{{ $cndi.get_prompt_response(deployment_target_provider) }}/core-prompts.yaml):
      {}

outputs:
  cndi_config:
    cndi_version: v2
    project_name: "{{ $cndi.get_prompt_response(project_name) }}"
    provider: "{{ $cndi.get_prompt_response(deployment_target_provider) }}"
    distribution: "{{ $cndi.get_prompt_response(deployment_target_distribution) }}"
    infrastructure:
      cndi:
        $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/common/cluster/observability-config.yaml):
          condition:
            - "{{ $cndi.get_prompt_response(deploy_grafana_ingress) }}"
            - ==
            - true

        $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/common/cluster/argocd-config.yaml):
          condition:
            - "{{ $cndi.get_prompt_response(deploy_argocd_ingress) }}"
            - ==
            - true

        cert_manager:
          email: "{{ $cndi.get_prompt_response(cert_manager_email) }}"

        external_dns:
          $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/external-dns/config/{{ $cndi.get_prompt_response(dns_provider) }}.yaml):
            condition:
              - "{{ $cndi.get_prompt_response(enable_external_dns) }}"
              - ==
              - true

        $cndi.get_block({{ $cndi.get_prompt_response(deployment_target_provider) }}-nodes):
          {}

    cluster_manifests:
      gpu-operator-ns:
        apiVersion: v1
        kind: Namespace
        metadata:
          name: gpu-operator

      external-dns-secret:
        $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/external-dns/secret/{{ $cndi.get_prompt_response(dns_provider) }}.yaml):
          condition:
            - "{{ $cndi.get_prompt_response(enable_external_dns) }}"
            - ==
            - true

      cuda-test:
        apiVersion: v1
        kind: Pod
        metadata:
          name: cuda-vectoradd
          namespace: gpu-operator
        spec:
          restartPolicy: OnFailure
          containers:
            - name: cuda-vectoradd
              image: "nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04"
              resources:
                limits:
                  nvidia.com/gpu: 1

        gpu-operator-quota:
          $cndi.get_block(gcp-resource-quota):
            condition:
              - "{{ $cndi.get_prompt_response(deployment_target_provider) }}"
              - ==
              - gcp

    applications:
      gpu-operator:
        repoURL: https://helm.ngc.nvidia.com/nvidia
        chart: gpu-operator
        targetRevision: v24.9.0
        destinationNamespace: gpu-operator
        values: {} # https://github.com/NVIDIA/gpu-operator/blob/master/deployments/gpu-operator/values.yaml

  env:
    $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/common/git-credentials-{{ $cndi.get_prompt_response(git_credentials_mode) }}-env.yaml):
      {}
    $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/{{ $cndi.get_prompt_response(deployment_target_provider) }}/env.yaml):
      {}
    $cndi.get_block(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/common/cluster/env.yaml):
      {}

  readme:
    project_name: "# {{ $cndi.get_prompt_response(project_name) }}"
    $cndi.get_string(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/common/cluster/core-readme.md):
      {}
    $cndi.get_string(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/{{ $cndi.get_prompt_response(deployment_target_provider) }}/core.md):
      {}
    $cndi.get_string(https://raw.githubusercontent.com/polyseam/cndi/main/blocks/{{ $cndi.get_prompt_response(deployment_target_provider) }}/{{ $cndi.get_prompt_response(deployment_target_distribution) }}.md):
      {}

    basic: |
      ## gpu-operator

      The [gpu-operator](https://github.com/nvidia/gpu-operator) is a Kubernetes operator will automatically add capacity information to your Kubernetes nodes which denotes that a GPU is present.

      To see an example workload, check out the `cuda-vectoradd` pod in the `gpu-operator` namespace.
